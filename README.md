# Keplet CLI
> Building machine learning is hard. Using it shouldn't be.

Keplet is a non-intrusive CLI for developing and interacting with machine learning projects by scafolding common architectures and abstracting model management (e.g. dependencies, documentation, containerization). Keplet supports any model architecture and is compatible with any framework, making it easier to publish reproducable models and deploy pre-trained instances.

## Features
- Virtual environments provisioner for environment variables and dependencies
- Dataset directory cache for use across multiple projects
- File directory usage for project management
- Command line documentation (by using the `--help` flag)
- Automatic REST API creation for model predictions over HTTP

## Example
Creating new project: `keplet create chatbot --framework torch`

```
ðŸ¤– New project named 'chatbot':
âœ¨ Creating folder with kep.json...
âœ¨ Cloning boilerplate files...
âœ¨ Creating virtual environment...
âœ¨ Generating README file...
âœ¨ Installing torch...

ðŸ¤– Success! Access your project by running:
 0. cd chatbot
 1. source venv/bin/activate
 2. pip install -r requirements.txt
 3. keplet start
```

Resulting project architecture (with PyTorch-enabled virtual environment):

    chatbot/
    â”œâ”€â”€ /venv                    # Virtual environment location
    â”œâ”€â”€ kep.json                 # Model/dataset definition and  misc. metadata
    â”œâ”€â”€ data.py                  # Data loader from either Keplet cache or by path
    â”œâ”€â”€ model.py                 # Model class with interface to make predictions
    â”œâ”€â”€ server.py                # REST API dynamically generated from kep.json config
    â”œâ”€â”€ requirements.txt         # Dependency tracker for use with pip/anaconda
    â”œâ”€â”€ Dockerfile               # Minimal Docker configuration for deployment
    â””â”€â”€ README.md                # Boilerplate README.md with file instructions

Additionally, running `keplet start` will launch a Flask server in `server.py`. By default, the server listens at `localhost:5000/predict` and returns JSON-encoded predictions over HTTP.

## Usage
After installing Keplet using `pip install keplet`:

```
Usage: manage.py [OPTIONS] COMMAND [ARGS]...

Options:
  --help  Learn more about the standard Keplet commands.

Commands:
  init
  list
  create
  start
  train
  predict
  containerize
  run
```

Where `run` can execute scripts defined in `kep.json`. 

## License
MIT
